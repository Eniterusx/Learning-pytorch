{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 PyTorch Going modular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data\n",
    "\n",
    "Same data as before (pizza, steak, sushi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/get_data.py\n",
    "\"\"\"\n",
    "A function to fetch the training and testing data if it doesn't exist already.\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} already exists\")\n",
    "    return\n",
    "else:\n",
    "    print(f\"Creating {image_path} directory\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the data\n",
    "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    print(\"Downloading data...\")\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip the data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping data...\")\n",
    "    zip_ref.extractall(image_path)\n",
    "\n",
    "# Remove zip\n",
    "os.remove(data_path / \"pizza_steak_sushi.zip\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create `Dataset`s and `DataLoader`s\n",
    "\n",
    "We create a `create_dataloaders()` function to do the job for us :D\n",
    "\n",
    "Then we write it to file using the line `%%writefile going_modular/data_setup.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for image classification data.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int = NUM_WORKERS\n",
    "):\n",
    "    \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "    Takes in a training directory and testing directory path and turns\n",
    "    them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "    Args:\n",
    "        train_dir: Path to training directory.\n",
    "        test_dir: Path to testing directory.\n",
    "        transform: torchvision transforms to perform on training and testing data.\n",
    "        batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "        num_workers: An integer for number of workers per DataLoader.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "\n",
    "    Example usage:\n",
    "        train_dataloader, test_dataloader, class_names = \\\n",
    "            = create_dataloaders(train_dir=path/to/train_dir,\n",
    "                                test_dir=path/to/test_dir,\n",
    "                                transform=some_transform,\n",
    "                                batch_size=32,\n",
    "                                num_workers=4)\n",
    "    \"\"\"\n",
    "\n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "    # Get class names\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    # Turn images into data loaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True,\n",
    "        num_workers = num_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = num_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Utilizing `create_dataloaders()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the arguments\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data_setup.py and leverage newly created function\n",
    "from going_modular import data_setup\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=data_transform,\n",
    "                                                                               batch_size=BATCH_SIZE,\n",
    "                                                                               num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making a model (`model_builder.py`)\n",
    "\n",
    "No more creating the TinyVGG model over and over, time to build it once and just use the function to create an instance whenever we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Creates the TinyVGG architecture.\n",
    "    \n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "    \n",
    "    Args:\n",
    "        input_shape: An integer indicating number of input channels.\n",
    "        hidden_units: An integer indicating number of hidden units between layers.\n",
    "        output_shape: An integer indicating number of output units.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*13*13,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Utilizing `model_builder()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from going_modular import model_builder\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "model = model_builder.TinyVGG(input_shape=3,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1690, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating `train_step()` and `test_step()` functions and `train()` to combine them.\n",
    "\n",
    "In the last notebook, we had a few training functions:\n",
    "\n",
    "1. `train_step()` - takes in a model, a `DataLoader`, a loss function and an optimizer and trains the model on the `DataLoader`.\n",
    "2. `test_step()` - takes in a model, a `DataLoader` and a loss function and evaluates the model on the `DataLoader`.\n",
    "3. `train()` - peformos train and test steps together for a given number of epochs and returns a results dictionary.\n",
    "\n",
    "Since these will be the engine of our model training, we can put them all into a Python script called `engine.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Trains a PyTorch model for a single epoch.\n",
    "    \n",
    "    Turns a target PyTorch model to training mode and then\n",
    "    runs through all of the required training steps (forward\n",
    "    pass, loss calculation, optimizer step).\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to hep minimize the loss function.\n",
    "        device: A target device to compute on(e.g. \"cuda\" or \"cpu)\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy). For example:\n",
    "        \n",
    "        (0.1112, 0.8743)\"\"\"\n",
    "\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Send data to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "    \"\"\"Tests a PyTorch model for a single epoch.\n",
    "    \n",
    "    Turns a target PyTorch model to \"eval\" model and then performs\n",
    "    a forward pass on a testing dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy). For example:\n",
    "        \n",
    "    (0.0223, 0.8985)\n",
    "    \"\"\"\n",
    "\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels==y).sum().item() / len(test_pred_labels))\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "    \n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to be trained and tested.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for\n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "                    train_acc: [...],\n",
    "                    test_loss: [...],\n",
    "                    test_acc: [...]} \n",
    "        For example if training for epochs=2: \n",
    "                    {train_loss: [2.0616, 1.0537],\n",
    "                    train_acc: [0.3945, 0.3945],\n",
    "                    test_loss: [1.2641, 1.5706],\n",
    "                    test_acc: [0.3400, 0.2973]}\n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    \n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Utilizing `train_step()`, `test_step()` and `train()` functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf89fb57960e4bdc861746c456fb60dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.1063 | train_acc: 0.3047 | test_loss: 1.0983 | test_acc: 0.3116\n",
      "Epoch: 2 | train_loss: 1.0995 | train_acc: 0.3320 | test_loss: 1.0699 | test_acc: 0.5417\n",
      "Epoch: 3 | train_loss: 1.0863 | train_acc: 0.4922 | test_loss: 1.0801 | test_acc: 0.5227\n",
      "Epoch: 4 | train_loss: 1.0826 | train_acc: 0.4102 | test_loss: 1.0599 | test_acc: 0.5729\n",
      "Epoch: 5 | train_loss: 1.0630 | train_acc: 0.4141 | test_loss: 1.0612 | test_acc: 0.5540\n"
     ]
    }
   ],
   "source": [
    "from going_modular import engine\n",
    "\n",
    "# Use train() by calling it from engine.py\n",
    "results = engine.train(model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            optimizer=optimizer,\n",
    "            loss_fn=loss_fn,\n",
    "            epochs=EPOCHS,\n",
    "            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating a function to save the model (`utils.py`)\n",
    "\n",
    "We can create a function to save the model to a file, so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str):\n",
    "    \"\"\"Saves a PyTorch model to a target directory.\n",
    "    \n",
    "    Args:\n",
    "        model: A target PyTorch model to save.\n",
    "        target_dir: A directory for saving the model to.\n",
    "        model_name: A filename for the saved model. Should include\n",
    "            either \".pth\" or \".pt\" as the file extension.\n",
    "    \n",
    "    Example usage:\n",
    "    save_model(model=model_0,\n",
    "               target_dir=\"models\",\n",
    "               model_name=\"model_name.pth\")\n",
    "    \"\"\"\n",
    "    # Create target directory\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create model save path\n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
    "    model_save_path = target_dir_path / model_name\n",
    "\n",
    "    # Save the model state_dict()\n",
    "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(),\n",
    "               f=model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Utilizing `save_model()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: models\\05_model_0.pth\n"
     ]
    }
   ],
   "source": [
    "from going_modular import utils\n",
    "\n",
    "# Save the model to file\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"05_model_0.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting it all together\n",
    "\n",
    "PyTorch repositories often combine all of their functionality together in a `train.py` file.\n",
    "\n",
    "This file is essentially saying \"train the model using whatever data is available\".\n",
    "\n",
    "In our `train.py` file, we'll combine all of the functionality of the other Pythoc scripts we've created and use it to train a model.\n",
    "\n",
    "This way we can train a PyTorch model using a single line of code on the command line:\n",
    "\n",
    "```bash\n",
    "python train.py\n",
    "```\n",
    "\n",
    "To create `train.py` we'll go through the following steps:\n",
    "1. Import various dependencies, namely `torch`, `os`, `torchvision.transforms` and all of the script from the `going_modular` directory, `data_setup`, `engine`, `model_builder`, `utils`.\n",
    "2. Note: Since `train.py` will be inside the `going_modular` directory, we can import the other modules via `import ...` rather than `from going_modular import ...`.\n",
    "3. Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units (these could be set in the future via Python's `argparse`).\n",
    "4. Setup the training and test directories.\n",
    "5. Setup device-agnostic code.\n",
    "6. Create the necessary data transforms.\n",
    "7. Create the DataLoaders using `data_setup.py`.\n",
    "8. Create the model using `model_builder.py`.\n",
    "9. Setup the loss function and optimizer.\n",
    "10. Train the model using `engine.py`.\n",
    "11. Save the model using `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model using device-agnostic code\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Setup hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_UNITS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Setup directories\n",
    "train_dir = \"data/pizza_steak_sushi/train\"\n",
    "test_dir = \"data/pizza_steak_sushi/test\"\n",
    "\n",
    "# Setup target device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Create transforms\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create DataLoaders with hep from data_setup.py\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=data_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create model with hep from model_builder.py\n",
    "model = model_builder.TinyVGG(\n",
    "    input_shape=3,\n",
    "    hidden_units=HIDDEN_UNITS,\n",
    "    output_shape=len(class_names)\n",
    ").to(device)\n",
    "\n",
    "# Set loss and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "\n",
    "# Start training with help from engine.py\n",
    "engine.train(model=model,\n",
    "             train_dataloader=train_dataloader,\n",
    "             test_dataloader=test_dataloader,\n",
    "             loss_fn=loss_fn,\n",
    "             optimizer=optimizer,\n",
    "             epochs=NUM_EPOCHS,\n",
    "             device=device)\n",
    "\n",
    "# Save the model with help from utils.py\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"models\",\n",
    "                 model_name=\"05_model_1.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 | train_loss: 1.1076 | train_acc: 0.3047 | test_loss: 1.0973 | test_acc: 0.2604\n",
      "\n",
      "Epoch: 2 | train_loss: 1.1033 | train_acc: 0.3008 | test_loss: 1.0700 | test_acc: 0.5417\n",
      "\n",
      "Epoch: 3 | train_loss: 1.1109 | train_acc: 0.2812 | test_loss: 1.0830 | test_acc: 0.2708\n",
      "\n",
      "Epoch: 4 | train_loss: 1.0815 | train_acc: 0.4883 | test_loss: 1.1068 | test_acc: 0.3854\n",
      "\n",
      "Epoch: 5 | train_loss: 1.0798 | train_acc: 0.3359 | test_loss: 1.1213 | test_acc: 0.2604\n",
      "[INFO] Saving model to: models\\05_model_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      " 20%|██        | 1/5 [00:19<01:18, 19.70s/it]\n",
      " 40%|████      | 2/5 [00:40<01:01, 20.43s/it]\n",
      " 60%|██████    | 3/5 [01:02<00:42, 21.01s/it]\n",
      " 80%|████████  | 4/5 [01:22<00:20, 20.71s/it]\n",
      "100%|██████████| 5/5 [01:42<00:00, 20.29s/it]\n",
      "100%|██████████| 5/5 [01:42<00:00, 20.42s/it]\n"
     ]
    }
   ],
   "source": [
    "!python going_modular/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating a function to make predictions on new data (`predict.py`)\n",
    "\n",
    "Arguments:\n",
    "- `model_path` - the path to the trained model.\n",
    "- `image_path` - the path to the image to make predictions on.\n",
    "- `transform` - the image transform to use (optional).\n",
    "- `classes` - the classes the model is trained on (optional).\n",
    "- `device` - the device to make predictions on (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/predict.py\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from going_modular import model_builder\n",
    "\n",
    "def pred_and_plot_image(model_path: str,\n",
    "                        image_path: str,\n",
    "                        class_names: List[str] = None,\n",
    "                        transform: transforms.Compose = None,\n",
    "                        device: torch.device = \"cpu\"):\n",
    "    \"\"\"Makes a prediction on a target image with a trained model and\n",
    "    plots the image and prediction\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved PyTorch model.\n",
    "        image_path: Path to the image to make a prediction on.\n",
    "        class_names: An optional list of class names for the target dataset.\n",
    "        transform: An optional sequence of transformations to perform on the image.\n",
    "        device: A target device to perform the model prediction on.\n",
    "    \n",
    "    Returns:\n",
    "        None, plots an image and prediction.\n",
    "\n",
    "    Example usage:\n",
    "    pred_and_plot_image(model_path=\"models/model_0.pth\",\n",
    "                        image_path=\"data/pizza_steak_sushi/test/sushi/100810.jpg\",\n",
    "                        class_names=[\"pizza\", \"steak\", \"sushi\"],\n",
    "                        transform=data_transform,\n",
    "                        device=\"cuda\")\n",
    "    \"\"\"\n",
    "    # Create new model\n",
    "    # Hardcoding the model type and hidden_units because I can :)\n",
    "    model = model_builder.TinyVGG(input_shape=3,\n",
    "                                  hidden_units=10,\n",
    "                                  output_shape=3)\n",
    "    \n",
    "    # Load the model from path\n",
    "    model.load_state_dict(torch.load(f=model_path))\n",
    "\n",
    "    # Load an image, divide by 255 to normalize\n",
    "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32) / 255.\n",
    "\n",
    "    # Add the batch dimension\n",
    "    target_image = target_image.unsqueeze(0)\n",
    "\n",
    "    # Transform if necessary\n",
    "    if transform:\n",
    "        target_image = transform(target_image)\n",
    "\n",
    "    # Put model on the target device\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        target_image_pred = model(target_image.to(device))\n",
    "\n",
    "        target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # remove batch dimension, rearrange\n",
    "\n",
    "    if class_names:\n",
    "        target_label = class_names[torch.argmax(target_image_pred_probs)]\n",
    "        title = f\"Pred: {target_label} | Prob: {target_image_pred_probs.max():.3f}\"\n",
    "    else:\n",
    "        title = f\"Pred: {torch.argmax(target_image_pred_probs)} | Prob: {target_image_pred_probs.max():.3f}\"    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from going_modular import predict\n",
    "\n",
    "custom_data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64,64)),\n",
    "])\n",
    "\n",
    "predict.pred_and_plot_image(model_path=\"models/05_model_1.pth\",\n",
    "                            image_path=\"data/04-pizza-dad.jpeg\",\n",
    "                            class_names=class_names,\n",
    "                            transform=custom_data_transform,\n",
    "                            device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
